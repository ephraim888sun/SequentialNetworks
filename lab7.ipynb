{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lab Assignment Seven: Sequential Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name 1: Jadon Swearingen (5000)\n",
    "Name 2: Ephraim Sun (7000)\n",
    "Name 3: Adeeb Abdul Taher (7000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will select a prediction task to perform on your dataset, evaluate a sequential architecture and tune hyper-parameters. If any part of the assignment is not clear, ask the instructor to clarify. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Selection\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/rajatkumar30/fake-news\n",
    "\n",
    "We have chosen a fake news dataset where given the title and text of the article, we should predict if the news is fake or real. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed). Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). Discuss methods of tokenization in your dataset as well as any decisions to force a specific length of sequence.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import re\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dropout, Layer, TextVectorization, Dense, GlobalMaxPooling1D, MultiHeadAttention, LayerNormalization # type: ignore\n",
    "from tensorflow.keras.regularizers import l1_l2 # type: ignore\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding # type: ignore\n",
    "\n",
    "mpl.style.use(\"seaborn-v0_8-deep\")\n",
    "mpl.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"lines.linewidth\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"./dataset/news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(5000) # to help run the models faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "og_shape = df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data\n",
    "\n",
    "This function performs several preprocessing steps on the input DataFrame:\n",
    "1. Converts the 'title' and 'text' columns to string type to ensure consistency.\n",
    "2. Encodes the 'label' column, mapping 'FAKE' to 1 and 'REAL' to 0, to prepare for machine learning algorithms.\n",
    "3. Drops the 'Unnamed: 0' column which is often an artifact from reading files with an index.\n",
    "5. Clean the text by lowercasing everything, removing stopwords, removing non-alphabetic characters, removing contractions, and cleaning numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(txt):\n",
    "      \n",
    "    #Creates list of possible stopwords from nltk library\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    # Lowercase\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    txt = ' '.join([word for word in txt.split() if word not in (stop)])\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    txt = re.sub('[^a-z]',' ',txt)\n",
    "    return txt  \n",
    "\n",
    "def cleanNumbers(x):\n",
    "    digit_map = {\n",
    "        '0': 'zero',\n",
    "        '1': 'one',\n",
    "        '2': 'two',\n",
    "        '3': 'three',\n",
    "        '4': 'four',\n",
    "        '5': 'five',\n",
    "        '6': 'six',\n",
    "        '7': 'seven',\n",
    "        '8': 'eight',\n",
    "        '9': 'nine'\n",
    "    }\n",
    "    \n",
    "    x = re.sub('[0-9]{7,}', 'millions', x)\n",
    "    x = re.sub('[0-9]{4,6}', 'thousand', x)\n",
    "    x = re.sub('[0-9]{3}', 'hundred', x)\n",
    "    x = re.sub('[0-9]{2}', 'tens', x)\n",
    "    x = re.sub('[0-9]{1}', 'tens', x)\n",
    "    x = re.sub(r'\\b\\d\\b', lambda match: digit_map[match.group()], x)\n",
    "\n",
    "    return x\n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "\n",
    "def replaceContractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "\n",
    "size_mini = 1000\n",
    "\n",
    "def pre_process(df):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - df (pd.Dataframe): The DataFrame to be preprocessed\n",
    "\n",
    "    Returns: \n",
    "    - df (pd.DataFrame): The DataFrame after preprocessed\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    # Remove the 'Unnamed: 0' column, if it exists, as it's usually an artifact\n",
    "    df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "    \n",
    "    # Map 'label' values from 'FAKE'/'REAL' to 1/0\n",
    "    df[\"label\"] = df[\"label\"].map({\"FAKE\": 1, \"REAL\": 0})\n",
    "\n",
    "    df = df.loc[df['text'].str.len() > size_mini]\n",
    "\n",
    "    print(\"We have kept\", (df.shape[0]/og_shape[0])*100, \"% of the data\")\n",
    "\n",
    "    # Cleaning the text, numbers, and replacing contractions\n",
    "    df['text'] = df['text'].apply(cleanText)\n",
    "    df['text'] = df[\"text\"].apply(cleanNumbers)\n",
    "    df['text'] = df[\"text\"].apply(replaceContractions)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_characters(df, col_name):\n",
    "    \"\"\"\n",
    "    Adds a new column to the DataFrame containing the number of characters in each message.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame. The DataFrame to which the new column will be added.\n",
    "    - col_name: str. The name of the column containing the messages.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame. The original DataFrame with a new column added.\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"Characters\"] = df[col_name].apply(len)\n",
    "    return df\n",
    "\n",
    "\n",
    "def num_sentences(df, col_name):\n",
    "    \"\"\"\n",
    "    Adds a new column to the DataFrame containing the number of sentences in each message.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame. The DataFrame to which the new column will be added.\n",
    "    - col_name: str. The name of the column containing the messages.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame. The original DataFrame with a new column added.\n",
    "    \"\"\"\n",
    "    df[\"Sentences\"] = df[col_name].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def num_words(df, col_name):\n",
    "    \"\"\"\n",
    "    Adds a new column to the DataFrame containing the number of words in each message.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame. The DataFrame to which the new column will be added.\n",
    "    - col_name: str. The name of the column containing the messages.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame. The original DataFrame with a new column added.\n",
    "    \"\"\"\n",
    "    df[\"Words\"] = df[col_name].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot(df, col_name):\n",
    "    \"\"\"\n",
    "    Creates a pie plot to show the distribution of real and fake news in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame. The DataFrame containing the data.\n",
    "    - col_name: str. The name of the column containing the labels.\n",
    "\n",
    "    Returns:\n",
    "    - None. Displays a pie plot.\n",
    "    \"\"\"\n",
    "    sizes = df[\"label\"].value_counts()\n",
    "    labels = [\"Real\", \"Fake\"]\n",
    "    colors = [\"#ff9999\", \"#66b3ff\"]\n",
    "\n",
    "    plt.pie(\n",
    "        sizes,\n",
    "        autopct=\"%1.1f%%\",\n",
    "        colors=colors,\n",
    "        startangle=90,\n",
    "        explode=(0.1, 0),\n",
    "        shadow=True,\n",
    "    )\n",
    "\n",
    "    plt.title(\"Distribution of Real and Fake News in \" + col_name)\n",
    "    plt.legend(labels, title=\"News Type\", loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_features(df, features, col_name):\n",
    "    \"\"\"\n",
    "    Plot distributions of specified features in a DataFrame, comparing 'Real' and 'Fake' news.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - features: List of strings, names of the columns for which to plot the distributions.\n",
    "\n",
    "    Each feature's distribution is plotted in a separate row, with 'Real' news in blue and 'Fake' news in pink.\n",
    "    \"\"\"\n",
    "    # Create a figure with subplots arranged in 3 rows and 1 column\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(features), ncols=1, figsize=(15, 6 * len(features))\n",
    "    )\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        # Plot distribution for 'Real' news\n",
    "        sns.histplot(\n",
    "            df[df[\"label\"] == 0][feature],\n",
    "            kde=True,\n",
    "            color=\"#66b3ff\",\n",
    "            label=\"Real\",\n",
    "            ax=axes[i],\n",
    "        )\n",
    "        # Plot distribution for 'Fake' news\n",
    "        sns.histplot(\n",
    "            df[df[\"label\"] == 1][feature],\n",
    "            kde=True,\n",
    "            color=\"#ff9999\",\n",
    "            label=\"Fake\",\n",
    "            ax=axes[i],\n",
    "        )\n",
    "        # Setting the title for each subplot\n",
    "        axes[i].set_title(f\"{feature} Distribution for {col_name} dataset\")\n",
    "        # Setting the labels for each subplot\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel(\"Count\")\n",
    "        # Adding legend to each subplot\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pre_process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = num_characters(df, \"text\")\n",
    "df = num_sentences(df, \"text\")\n",
    "df = num_words(df, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot(df, \"Full Text Article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of the title column\n",
    "df_title = df\n",
    "\n",
    "df_title = num_characters(df_title, \"title\")\n",
    "df_title = num_sentences(df_title, \"title\")\n",
    "df_title = num_words(df_title, \"title\")\n",
    "\n",
    "plot_distribution_features(df_title, [\"Characters\", \"Sentences\", \"Words\"], \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of the text column\n",
    "df_text = df\n",
    "\n",
    "df_text = num_characters(df_text, \"text\")\n",
    "df_text = num_sentences(df_text, \"text\")\n",
    "df_text = num_words(df_text, \"text\")\n",
    "\n",
    "plot_distribution_features(df_text, [\"Characters\", \"Sentences\", \"Words\"], \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization And Sequence Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the decision to force a specific length of sequence, we determining the 95th percentile of the text lengths and used the value as the sequence length. This ensures that the majority of the texts are covered while also preventing excessively long sequences that may lead to memory issues or computational inefficiency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Determine the 95th percentile of these lengths\n",
    "sequence_length_95 = np.percentile(df['text_length'], 95)\n",
    "\n",
    "sequence_length = int(np.ceil(sequence_length_95))\n",
    "\n",
    "print(f\"Length covering at least 95% of the news: {sequence_length}\")\n",
    "df = df.drop(columns=[\"text_length\"])\n",
    "print(\"The kept sequence is:\", sequence_length, \"words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilized the TextVectorization layer for tokenization, which encompasses normalizing text to lowercase, stripping punctuation, limiting vocabulary size, controlling sequence length, adapting to the dataset, and mapping tokens to integer indices, thereby ensuring efficient text processing and numerical representation, thus enhancing model training and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "\n",
    "vectorization = TextVectorization(standardize=\"lower_and_strip_punctuation\", \n",
    "                                  max_tokens=max_features, \n",
    "                                  output_mode='int', \n",
    "                                  output_sequence_length=sequence_length)\n",
    "vectorization.adapt(df[\"text\"])\n",
    "\n",
    "words_database = vectorization.get_vocabulary()\n",
    "database_index = {word: index for index, word in enumerate(words_database)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decied to utilize Glove Twitter Embedding\n",
    "\n",
    "Details found here: https://www.kaggle.com/datasets/fullmetal26/glovetwitter27b100dtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_index():\n",
    "    EMBEDDING_FILE = 'glove.twitter.27B.200d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, 'r', encoding='utf-8'))\n",
    "    return embeddings_index\n",
    "\n",
    "glove_embedding_index_twitter = load_glove_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove(word_index, embeddings_index):\n",
    "    all_embs = list(embeddings_index.values())  # Convert values to list\n",
    "    embed_size = all_embs[0].shape[0]  # Assuming all embeddings have the same size\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(0, 1, (nb_words, embed_size))\n",
    "\n",
    "    count_found = nb_words\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] =  embedding_vector\n",
    "        else:\n",
    "            if word.islower():\n",
    "                embedding_vector = embeddings_index.get(word.capitalize())\n",
    "                if embedding_vector is not None: \n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                else:\n",
    "                    count_found -= 1\n",
    "            else:\n",
    "                count_found -= 1\n",
    "    print(\"We found\", count_found, \"words\")\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_glove_twitter = create_glove(database_index, glove_embedding_index_twitter)\n",
    "\n",
    "embedding_dim = 200\n",
    "embedding_layer = Embedding(input_dim=max_features, output_dim=embedding_dim, weights=[adapted_glove_twitter], input_length=sequence_length, trainable=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided on the following metrics\n",
    "\n",
    "Precision: Precision is the ratio of true positive predictions (correctly identifying fake news) to the total number of positive predictions (both true positives and false positives).\n",
    "\n",
    "Recall (Sensitivity): Recall is the ratio of true positive predictions to the total number of actual positive instances (both true positives and false negatives).\n",
    "\n",
    "F1 Score: The F1 score is the harmonic mean of precision and recall. It provides a balanced assessment of the algorithm's performance by taking both precision and recall into account.\n",
    "\n",
    "Specificity: Specificity is the ratio of true negative predictions (correctly identifying real news) to the total number of actual negative instances (both true negatives and false positives).\n",
    "\n",
    "Area Under the Receiver Operating Characteristic Curve (AUC-ROC): The AUC-ROC measures the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) at various classification thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your train/test splitting method is a realistic mirroring of how an algorithm would be used in practice. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows, total_columns = df.shape\n",
    "print(\"Total number of rows:\", total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to utilize a 80/20 split:\n",
    "\n",
    "Given the balanced output distribution between fake and real data in the dataset comprising 5405 rows, employing an 80/20 train/test split offers a pragmatic approach to model development and evaluation. This split dedicates the bulk of the data, approximately 80%, to training, facilitating the learning of intricate patterns and representations within the dataset. The remaining 20% serves as a separate test set, enabling robust assessment of the model's generalization performance on unseen data. Such an allocation strikes a balance between providing ample training data for effective model learning and maintaining a sufficiently sized test set for reliable performance evaluation, essential for ensuring the model's efficacy in discerning between real and fake data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3 points] Investigate at least two different sequential network architectures (e.g., a CNN and a Transformer). Alternatively, you may also choose a recurrent network and Transformer network. Be sure to use an embedding layer (try to use a pre-trained embedding, if possible). Adjust one hyper-parameter of each network to potentially improve generalization performance (train a total of at least four models). Visualize the performance of training and validation sets versus the training iterations, showing that the models converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN Model\n",
    "def rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))  # Input layer for raw strings\n",
    "    model.add(vectorization)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(128, return_sequences=True))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "def lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))  # Input layer for raw strings\n",
    "    model.add(vectorization)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_model():\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))  # Input layer for raw strings\n",
    "    model.add(vectorization)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(GRU(128, return_sequences=True))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taken from https://github.com/eclarson/MachineLearningNotebooks/blob/master/13a.%20Sequence%20Basics%20%5Bexperimental%5D.ipynb\n",
    "\n",
    "# The transformer architecture \n",
    "class TransformerBlock(Layer): # inherit from Keras Layer\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2):\n",
    "        super().__init__()\n",
    "        # setup the model heads and feedforward network\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, \n",
    "                                      key_dim=embed_dim)\n",
    "        \n",
    "        # make a two layer network that processes the attention\n",
    "        self.ffn = Sequential()\n",
    "        self.ffn.add( Dense(ff_dim, activation='relu') )\n",
    "        self.ffn.add( Dense(embed_dim) )\n",
    "        \n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # apply the layers as needed (similar to PyTorch)\n",
    "        \n",
    "        # get the attention output from multi heads\n",
    "        # Using same inpout here is self-attention\n",
    "        # call inputs are (query, value, key) \n",
    "        # if only two inputs given, value and key are assumed the same\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        \n",
    "        # create residual output, with attention\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        \n",
    "        # apply dropout if training\n",
    "        out1 = self.dropout1(out1, training=training)\n",
    "        \n",
    "        # place through feed forward after layer norm\n",
    "        ffn_output = self.ffn(out1)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        # apply dropout if training\n",
    "        out2 = self.dropout2(out2, training=training)\n",
    "        #return the residual from Dense layer\n",
    "        return out2\n",
    "    \n",
    "    \n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        # create two embeddings \n",
    "        # one for processing the tokens (words)\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, \n",
    "                                   output_dim=embed_dim)\n",
    "        # another embedding for processing the position\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, \n",
    "                                 output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        # create a static position measure (input)\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        # positions now goes from 0 to 500 (for IMdB) by 1\n",
    "        positions = self.pos_emb(positions)# embed these positions\n",
    "        x = self.token_emb(x) # embed the tokens\n",
    "        return x + positions # add embeddngs to get final embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_model():\n",
    "    embed_dim = embedding_dim  # Assuming you are using GloVe embeddings with dimension 200\n",
    "    num_heads = 1\n",
    "    ff_dim = 32\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)  # Use dtype=tf.string for token sequences\n",
    "    x = inputs\n",
    "    x = TokenAndPositionEmbedding(sequence_length, max_features, embed_dim)(x)\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, train_df, test_df, epochs=20):\n",
    "\n",
    "    model.summary()\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model and store the training history\n",
    "    history = model.fit(train_df['text'], train_df['label'], epochs=epochs, validation_data=(test_df['text'], test_df['label']))\n",
    "\n",
    "    # Return the training history and the trained model\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the training and validation accuracy and loss\n",
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variations = [\n",
    "    (rnn_model),\n",
    "    (lstm_model),\n",
    "    (gru_model),\n",
    "    # (transformer_model) - Added below b/c different architecture\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate all model variations\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "histories = []\n",
    "models = []\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=10)\n",
    "\n",
    "\n",
    "for model_func in model_variations:\n",
    "    _model = model_func()\n",
    "    history, model = train_and_evaluate_model(model=_model, train_df=train_df, test_df=test_df, epochs=epochs)\n",
    "    histories.append(history)\n",
    "    models.append(model)\n",
    "\n",
    "# Add the transformer model to the list of models\n",
    "train_sequences = vectorization(train_df['text'])\n",
    "test_sequences = vectorization(test_df['text'])\n",
    "\n",
    "trans_model = transformer_model()\n",
    "\n",
    "trans_model.summary()\n",
    "trans_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "trans_history = trans_model.fit(train_sequences, train_df['label'], epochs=epochs, validation_data=(test_sequences, test_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the performance of all model variations\n",
    "for i, history in enumerate(histories):\n",
    "    model_func = model_variations[i]\n",
    "    title = f\"{model_func.__name__}\"\n",
    "    plot_history(history, title=f\"{title}\")\n",
    "\n",
    "# Plot Transformer Model as well\n",
    "plot_history(trans_history, title=f\"Transformer Model With 1 Multi-headed Self Attention Layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Using the best parameters and architecture from the Transformer in the previous step, add a second Multi-headed self attention layer to your network. That is, the input to the second attention layer should be the output sequence of the first attention layer.  Visualize the performance of training and validation sets versus the training iterations, showing that the model converged.. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_model2():\n",
    "    embed_dim = embedding_dim  # Assuming you are using GloVe embeddings with dimension 200\n",
    "    num_heads = 2\n",
    "    ff_dim = 32\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)  # Use dtype=tf.string for token sequences\n",
    "    x = inputs\n",
    "    x = TokenAndPositionEmbedding(sequence_length, max_features, embed_dim)(x)\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model2 = transformer_model2()\n",
    "\n",
    "trans_model2.summary()\n",
    "trans_model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "trans_history2 = trans_model2.fit(train_sequences, train_df['label'], epochs=epochs, validation_data=(test_sequences, test_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the performance for Transformer Model 2\n",
    "plot_history(trans_history2, title=f\"Transformer With 2 Multi-headed Self Attention Layer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2 points] Use the method of train/test splitting and evaluation criteria that you argued for at the beginning of the lab. Visualize the results of all the models you trained.  Use proper statistical comparison techniques to determine which method(s) is (are) superior.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for all model variations\n",
    "evaluation_results = []\n",
    "\n",
    "\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    y_pred = model.predict(X_test)  # Assuming X_test and y_test are the test data\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    recall = recall_score(y_test, y_pred_binary)\n",
    "    f1 = f1_score(y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_binary).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    evaluation_results.append((recall, f1, specificity, auc_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in evaluation_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_for_transformer_model(trans_model):\n",
    "    X_test = test_sequences\n",
    "    y_pred = trans_model.predict(X_test) \n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    recall = recall_score(y_test, y_pred_binary)\n",
    "    f1 = f1_score(y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_binary).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return [recall, f1, specificity, auc_roc]\n",
    "\n",
    "evaluation_results_transformer_1 = calculate_metrics_for_transformer_model(trans_model)\n",
    "evaluation_results_transformer_2 = calculate_metrics_for_transformer_model(trans_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the evaluation metrics\n",
    "metric_names = ['Recall', 'F1 Score', 'Specificity', 'AUC-ROC']\n",
    "\n",
    "for idx, (model_func) in enumerate(model_variations):\n",
    "    title = f\"{model_func.__name__}\"\n",
    "    plt.suptitle(title)\n",
    "    for j, metric_name in enumerate(metric_names):\n",
    "        metric_value = evaluation_results[idx][j]\n",
    "        plt.subplot(1, len(metric_names), j+1)\n",
    "        plt.boxplot([metric_value])\n",
    "        plt.title(metric_name)\n",
    "        plt.xlabel('Model Variation')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Transformer 1\n",
    "plt.suptitle(f\"Transformer Model with 1 Multi-Head\")\n",
    "for j, metric_name in enumerate(metric_names):\n",
    "    metric_value = evaluation_results_transformer_1[j]\n",
    "    plt.subplot(1, len(metric_names), j+1)\n",
    "    plt.boxplot([metric_value])\n",
    "    plt.title(metric_name)\n",
    "    plt.xlabel('Model Variation')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Transformer 2\n",
    "plt.suptitle(f\"Transformer Model with 2 Multi-Head\")\n",
    "for j, metric_name in enumerate(metric_names):\n",
    "    metric_value = evaluation_results_transformer_2[j]\n",
    "    plt.subplot(1, len(metric_names), j+1)\n",
    "    plt.boxplot([metric_value])\n",
    "    plt.title(metric_name)\n",
    "    plt.xlabel('Model Variation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title=\"Confusion matrix\"):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], \"d\"),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Real\", \"Fake\"]\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    model_func = model_variations[i]\n",
    "    title = f\"{model_func.__name__}\"\n",
    "\n",
    "    ml_model = model_func()\n",
    "    pred = ml_model.predict(test_df['text'])\n",
    "    pred_classes = (pred > 0.5).astype(int)\n",
    "\n",
    "    conf_matrix = confusion_matrix(test_df['label'], pred_classes)\n",
    "    plot_confusion_matrix(conf_matrix, classes, title)\n",
    "\n",
    "# Transformer Model with 1 Multi-Head\n",
    "predictions1 = trans_model.predict(test_sequences)\n",
    "predicted_labels1 = (predictions1 > 0.5).astype(int)\n",
    "trans_conf_matrix = confusion_matrix(test_df['label'], predicted_labels1)\n",
    "plot_confusion_matrix(trans_conf_matrix, classes, title=\"Transformer Model With 1 Multi-Head\")\n",
    "\n",
    "# Transformer Model with 2 Multi-Head\n",
    "predictions2 = trans_model2.predict(test_sequences)\n",
    "predicted_labels2 = (predictions2 > 0.5).astype(int)\n",
    "trans_conf_matrix2 = confusion_matrix(test_df['label'], predicted_labels2)\n",
    "plot_confusion_matrix(trans_conf_matrix2, classes, title=\"Transformer Model With 2 Multi-Head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pre-trained ConceptNet Numberbatch embedding and compare to pre-trained GloVe. Which method is better for your specific application? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_embedding_matrix(glove_embeddings, max_features, embedding_dim):\n",
    "    embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "    for word, i in database_index.items():\n",
    "        if i < max_features:\n",
    "            embedding_vector = glove_embeddings.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(file):\n",
    "    embeddings = {}\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = coefs\n",
    "    return embeddings\n",
    "\n",
    "glove_embeddings = load_glove_embeddings('glove.6B.100d.txt')\n",
    "\n",
    "glove_embedding_matrix = prepare_embedding_matrix(glove_embeddings, max_features, embedding_dim=100)\n",
    "\n",
    "glvoe_embedding_layer = Embedding(input_dim=max_features, output_dim=100, weights=[glove_embedding_matrix], input_length=sequence_length, trainable=False)\n",
    "\n",
    "# Define a model using the GloVe embeddings\n",
    "def model_with_glove_embeddings():\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))  # Input layer for raw strings\n",
    "    model.add(vectorization)\n",
    "    model.add(glvoe_embedding_layer)\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ConceptNet Numberbatch embeddings\n",
    "def load_numberbatch_embeddings(file):\n",
    "    embeddings = {}\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = coefs\n",
    "    return embeddings\n",
    "\n",
    "numberbatch_embeddings = load_numberbatch_embeddings('numberbatch-en-19.08.txt')\n",
    "\n",
    "numberbatch_embedding_matrix = prepare_embedding_matrix(numberbatch_embeddings, max_features, embedding_dim=300)\n",
    "\n",
    "numberbatch_embedding_layer = Embedding(input_dim=max_features, output_dim=300, weights=[numberbatch_embedding_matrix], input_length=sequence_length, trainable=False)\n",
    "\n",
    "# Define a model using the Numberbatch embeddings\n",
    "def model_with_numberbatch_embeddings():\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))  # Input layer for raw strings\n",
    "    model.add(vectorization)\n",
    "    model.add(numberbatch_embedding_layer)\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, train_df, test_df, epochs=20):\n",
    "    \n",
    "    model.summary()\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model and store the training history\n",
    "    # history = model.fit(train_sequences, train_df['label'], epochs=epochs, validation_data=(test_sequences, test_df['label']))\n",
    "    history = model.fit(train_df['text'], train_df['label'], epochs=epochs, validation_data=(test_df['text'], test_df['label']))\n",
    "\n",
    "\n",
    "    # Return the training history and the trained model\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of classes\n",
    "classes = [\"Real\", \"Fake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the Glove model\n",
    "model1 = model_with_glove_embeddings()\n",
    "\n",
    "history1, model = train_and_evaluate_model(model1, train_df=train_df, test_df=test_df, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test data\n",
    "y_pred = model.predict(test_df['text'])\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Plot confusion matrix for Glove model\n",
    "plot_confusion_matrix(cm1, classes, title='Confusion Matrix - Glove Model')\n",
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "plot_history(history1, title='Model with Glove embeddings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the ConceptNet model\n",
    "model2 = model_with_numberbatch_embeddings()\n",
    "history2, model2 = train_and_evaluate_model(model2, train_df=train_df, test_df=test_df, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test data\n",
    "y_pred = model2.predict(test_df['text'])\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm2 = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Plot confusion matrix for ConceptNet model\n",
    "plot_confusion_matrix(cm2, classes, title='Confusion Matrix - ConceptNet Model')\n",
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "plot_history(history2, title='Model with ConceptNet Numberbatch embeddings')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
